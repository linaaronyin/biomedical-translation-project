{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":8331,"status":"ok","timestamp":1733539708264,"user":{"displayName":"Aaron Lin","userId":"11593436174117725897"},"user_tz":480},"id":"hpfUJY42OHfc","outputId":"c55d1faa-4a4c-4ea5-9e8b-54ed08bbfc2f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting huggingface\n","  Downloading huggingface-0.0.1-py3-none-any.whl.metadata (2.9 kB)\n","Collecting rouge_score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting bert_score\n","  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.9.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.5.1+cu121)\n","Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.2.2)\n","Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.46.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.32.3)\n","Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.66.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert_score) (3.8.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert_score) (24.2)\n","Collecting portalocker (from sacrebleu)\n","  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2024.9.11)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n","Collecting colorama (from sacrebleu)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (5.3.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2024.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score) (1.3.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.26.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (6.0.2)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.20.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.4.5)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (4.55.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.4.7)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (11.0.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (3.2.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2024.8.30)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.2)\n","Downloading huggingface-0.0.1-py3-none-any.whl (2.5 kB)\n","Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Downloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n","Building wheels for collected packages: rouge_score\n","  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=422cba473c328bebd3b6b9515e6c12874f9636cf6a4624be35f0738c8aa94371\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","Successfully built rouge_score\n","Installing collected packages: huggingface, portalocker, colorama, sacrebleu, rouge_score, bert_score\n","Successfully installed bert_score-0.3.13 colorama-0.4.6 huggingface-0.0.1 portalocker-3.0.0 rouge_score-0.1.2 sacrebleu-2.4.3\n"]}],"source":["pip install huggingface rouge_score bert_score sacrebleu"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":3389,"status":"ok","timestamp":1733539711649,"user":{"displayName":"Aaron Lin","userId":"11593436174117725897"},"user_tz":480},"id":"OPNcQ2SBQYFp","outputId":"13f0374f-0773-4972-f522-06742cb3ab24"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n","Collecting evaluate\n","  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.9)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets, evaluate\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 evaluate-0.4.3 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"]}],"source":["pip install datasets transformers evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35293,"status":"ok","timestamp":1733539746938,"user":{"displayName":"Aaron Lin","userId":"11593436174117725897"},"user_tz":480},"id":"9zdAKxG1Qwyf","outputId":"d3b7d75a-624f-4a8e-a623-2f9683607aa4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","# Mount your Google Drive\n","drive.mount('/content/drive')\n","\n","# Define the data directory inside your Google Drive\n","# data_dir = \"/content/drive/My Drive/Colab Notebooks/corpora\"\n","data_dir = \"/content/drive/My Drive/266 Data Project/corpora\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NWQmaXceO-HR"},"outputs":[],"source":["import torch\n","from torch import nn\n","from transformers import MarianMTModel, MarianTokenizer, Seq2SeqTrainer, Seq2SeqTrainingArguments\n","import pandas as pd\n","from datasets import Dataset, load_dataset\n","import torch.nn.functional as F\n","import os\n","import json\n","os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n","os.environ[\"PYTORCH_USE_CUDA_DSA\"] = \"1\"\n","\n","def load_marian_with_biomedical_layer(model_name, hidden_size, special_tokens):\n","    # Load tokenizer and add special tokens\n","    tokenizer = MarianTokenizer.from_pretrained(model_name)\n","    tokenizer.add_special_tokens({\n","        'additional_special_tokens': list(set(special_tokens))\n","    })\n","\n","    # Load base model\n","    model = MarianMTModel.from_pretrained(model_name)\n","\n","    # Create custom model, CustomMarianMTModel will create a BiomedicalEncoder object in init()\n","    custom_model = CustomMarianMTModel(\n","        config=model.config,\n","        hidden_size=hidden_size,\n","        special_token_size=len(special_tokens),\n","    )\n","\n","\n","    # Resize token embeddings\n","    custom_model.resize_token_embeddings(len(tokenizer))\n","\n","    return tokenizer, custom_model\n","\n","class BiomedicalEncoder(nn.Module):\n","    def __init__(self, hidden_size, special_token_size):\n","        super(BiomedicalEncoder, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.special_token_size = special_token_size\n","\n","        # Adjust the linear layer to match input dimensions\n","        self.linear = nn.Linear(special_token_size, hidden_size)\n","        self.activation = nn.ReLU()\n","\n","    def forward(self, entity_embeddings):\n","        # Reshape entity embeddings if necessary\n","        original_shape = entity_embeddings.shape\n","\n","        # Flatten the tensor if it has more than 2 dimensions\n","        if len(original_shape) > 2:\n","            entity_embeddings = entity_embeddings.view(-1, original_shape[-1])\n","\n","        # Ensure the input matches the expected dimension\n","        if entity_embeddings.size(1) != self.special_token_size:\n","            # If the input doesn't match, pad or truncate\n","            if entity_embeddings.size(1) < self.special_token_size:\n","                # Pad with zeros\n","                padding = torch.zeros(\n","                    entity_embeddings.size(0),\n","                    self.special_token_size - entity_embeddings.size(1),\n","                    device=entity_embeddings.device\n","                )\n","                entity_embeddings = torch.cat([entity_embeddings, padding], dim=1)\n","            else:\n","                # Truncate\n","                entity_embeddings = entity_embeddings[:, :self.special_token_size]\n","\n","        # Apply linear transformation and activation\n","        encoded = self.linear(entity_embeddings)\n","        return self.activation(encoded)\n","\n","class CustomMarianMTModel(MarianMTModel):\n","    def __init__(self, config, hidden_size=512, special_token_size=206573, biomedicalEncoder=None):\n","        super().__init__(config)\n","        self.hidden_size = hidden_size\n","        self.special_token_size = special_token_size\n","\n","        # Initialize biomedical encoder within the model\n","        if biomedicalEncoder == None:\n","            self.biomedical_encoder = BiomedicalEncoder(hidden_size, special_token_size)\n","        else:\n","            self.biomedical_encoder = biomedicalEncoder\n","\n","        # Entity embedding for special tokens\n","        self.entity_embedding = nn.Embedding(special_token_size + 1, hidden_size)  # +1 for padding token\n","\n","        # Projection layer to match vocabulary size\n","        self.entity_projection = nn.Linear(hidden_size, config.vocab_size)\n","\n","    def save_custom(self, save_directory):\n","        # Create save directory if it doesn't exist\n","        os.makedirs(save_directory, exist_ok=True)\n","\n","        model_save_path = os.path.join(save_directory, \"model\")\n","        print(model_save_path)\n","        tokenizer_save_path = os.path.join(save_directory, \"tokenizer\")\n","\n","        os.makedirs(model_save_path, exist_ok=True)\n","        os.makedirs(tokenizer_save_path, exist_ok=True)\n","\n","        # Save the model and its configuration\n","        self.save_pretrained(model_save_path)\n","\n","        # Save the biomedical encoder's state_dict\n","        torch.save(self.biomedical_encoder.state_dict(), os.path.join(model_save_path, \"biomedical_encoder.pth\"))\n","\n","        # Save custom attributes in a JSON file\n","        custom_config = {\n","            \"hidden_size\": self.hidden_size,\n","            \"special_token_size\": self.special_token_size,\n","        }\n","        with open(os.path.join(model_save_path, \"custom_config.json\"), \"w\") as f:\n","            json.dump(custom_config, f)\n","\n","        if tokenizer is not None:\n","            tokenizer.save_pretrained(tokenizer_save_path)\n","\n","    @classmethod\n","    def from_custom(cls, save_directory):\n","        model_save_path = os.path.join(save_directory, \"model\")\n","        tokenizer_save_path = os.path.join(save_directory, \"tokenizer\")\n","\n","        # Load custom attributes from JSON\n","        custom_config_path = os.path.join(model_save_path, \"custom_config.json\")\n","        with open(custom_config_path, \"r\") as f:\n","            custom_config = json.load(f)\n","\n","        # Load base model configuration\n","        model = MarianMTModel.from_pretrained(model_save_path)\n","\n","        # Create a new CustomMarianMTModel with the loaded configuration\n","        new_model = cls(\n","            config=model.config,\n","            hidden_size=custom_config[\"hidden_size\"],\n","            special_token_size=custom_config[\"special_token_size\"]\n","        )\n","\n","        # Load the biomedical encoder state dict\n","        biomedical_encoder_path = os.path.join(model_save_path, \"biomedical_encoder.pth\")\n","        biomedical_encoder_state_dict = torch.load(biomedical_encoder_path)\n","        new_model.biomedical_encoder.load_state_dict(biomedical_encoder_state_dict)\n","\n","        # Load the main model weights\n","        state_dict = model.state_dict()\n","        new_model_state_dict = new_model.state_dict()\n","\n","        # Update the state dictionary, keeping the biomedical encoder weights\n","        for key, value in state_dict.items():\n","            if key in new_model_state_dict:\n","                new_model_state_dict[key] = value\n","\n","        new_model.load_state_dict(new_model_state_dict, strict=False)\n","\n","        # Load tokenizer\n","        tokenizer = MarianTokenizer.from_pretrained(tokenizer_save_path)\n","\n","        return new_model, tokenizer\n","\n","    def forward(self, input_ids=None, attention_mask=None, labels=None, entity_ids=None, **kwargs):\n","        # Perform base MarianMT forward pass\n","        outputs = super().forward(input_ids=input_ids, attention_mask=attention_mask, labels=labels, **kwargs)\n","\n","        # Process entity information if provided\n","        if entity_ids is not None:\n","            try:\n","                # Ensure entity_ids is a tensor with 2 dimensions\n","                if len(entity_ids.shape) == 1:\n","                    entity_ids = entity_ids.unsqueeze(0)\n","\n","                # Get batch size, sequence length, and vocab size from outputs\n","                batch_size = outputs.logits.size(0)\n","                sequence_length = outputs.logits.size(1)\n","                vocab_size = outputs.logits.size(2)\n","\n","                # Ensure entity_ids is on the same device as outputs.logits\n","                entity_ids = entity_ids.to(outputs.logits.device)\n","\n","                # Limit entity_ids to current batch size\n","                entity_ids = entity_ids[:batch_size]\n","\n","                if torch.any(entity_ids >= self.entity_embedding.num_embeddings):\n","                    print(f\"Invalid entity IDs detected: {entity_ids}\")\n","                    raise ValueError(\"Entity IDs are out of bounds for the embedding layer\")\n","\n","\n","                # Get embeddings for entity special tokens\n","                entity_embeddings = self.entity_embedding(entity_ids)\n","\n","                # Ensure embeddings are on the correct device\n","                entity_embeddings = entity_embeddings.to(outputs.logits.device)\n","\n","                # Process through biomedical encoder\n","                original_shape = entity_embeddings.shape\n","                entity_features = self.biomedical_encoder(entity_embeddings.view(-1, original_shape[-1]))\n","\n","                # Reshape back to original batch and entity dimension\n","                entity_features = entity_features.view(original_shape[0], original_shape[1], -1)\n","\n","                # Project entity features to match logits dimensionality\n","                entity_logits = self.entity_projection(entity_features)\n","\n","                # Ensure logits are on the correct device\n","                entity_logits = entity_logits.to(outputs.logits.device)\n","\n","                # Create a tensor of zeros with the same shape as outputs.logits\n","                expanded_entity_logits = torch.zeros_like(outputs.logits)\n","\n","                # Adjust logits shape to match the entity length\n","                min_entities = min(entity_logits.size(1), expanded_entity_logits.size(1))\n","                min_vocab = min(entity_logits.size(2), expanded_entity_logits.size(2))\n","\n","                expanded_entity_logits[:, :min_entities, :min_vocab] = entity_logits[:, :min_entities, :min_vocab]\n","\n","                # Add entity-based logits to original logits\n","                outputs.logits = outputs.logits + expanded_entity_logits\n","\n","            except Exception as e:\n","                print(f\"Error in forward method: {e}\")\n","                raise\n","        torch.cuda.synchronize()\n","        return outputs\n","\n","\n","\n","def prepare_dataset(dataset, tokenizer, src_lang=\"chinese\", tgt_lang=\"english\", max_entities=5):\n","    def preprocess_function(examples):\n","        # Ensure inputs are lists\n","        src_sentences = examples[src_lang]\n","        tgt_sentences = examples[tgt_lang]\n","        entities_list = examples.get(\"entities\", [[] for _ in src_sentences])\n","\n","        processed_src = []\n","        processed_entities = []\n","\n","        for sentence, entities in zip(src_sentences, entities_list):\n","            # Ensure sentence is a string and remove existing spaces\n","            sentence = str(sentence).replace(\" \", \"\")\n","\n","            processed_src.append(sentence)\n","\n","            # Convert entities to token IDs\n","            entity_ids = [\n","                tokenizer.convert_tokens_to_ids(f\"{entity}\")\n","                for entity in entities\n","            ]\n","\n","            # Pad or truncate entity_ids\n","            entity_ids = entity_ids[:max_entities]\n","            entity_ids += [0] * (max_entities - len(entity_ids))\n","            processed_entities.append(entity_ids)\n","\n","        # Tokenize source sentences\n","        model_inputs = tokenizer(\n","            processed_src,\n","            max_length=512,\n","            truncation=True,\n","            padding=\"max_length\",  # Ensure uniform length\n","            return_tensors=\"pt\"\n","        )\n","\n","        # Tokenize target sentences\n","        labels = tokenizer(\n","            tgt_sentences,\n","            max_length=512,\n","            truncation=True,\n","            padding=\"max_length\",  # Ensure uniform length\n","            return_tensors=\"pt\"\n","        )\n","\n","        # Add labels to model inputs, and replace padding tokens with -100 for loss masking\n","        model_inputs[\"labels\"] = labels[\"input_ids\"]\n","        model_inputs[\"labels\"][model_inputs[\"labels\"] == tokenizer.pad_token_id] = -100\n","\n","        # Convert entity_ids to tensor\n","        model_inputs[\"entity_ids\"] = torch.tensor(processed_entities, dtype=torch.long)\n","\n","        return model_inputs\n","\n","    # Apply preprocessing to the dataset\n","    processed_dataset = dataset.map(\n","        preprocess_function,\n","        batched=True,\n","        remove_columns=dataset.column_names\n","    )\n","\n","    return processed_dataset\n","\n","def fine_tune_custom_model(custom_model, tokenizer, tokenized_dataset, output_dir):\n","    # Split dataset\n","    dataset = tokenized_dataset.train_test_split(test_size=0.1)\n","\n","    training_args = Seq2SeqTrainingArguments(\n","        output_dir=output_dir,\n","        evaluation_strategy=\"epoch\",\n","        learning_rate=5e-5,\n","        per_device_train_batch_size=8,\n","        gradient_accumulation_steps=2,\n","        per_device_eval_batch_size=8,\n","        num_train_epochs=1,\n","        save_strategy=\"epoch\",\n","        save_safetensors=False,\n","        logging_dir=f\"{output_dir}/logs\",\n","        logging_steps=100,\n","        predict_with_generate=True,\n","        push_to_hub=False,\n","        fp16=True  # Disable mixed precision\n","    )\n","\n","    # Create trainer\n","    trainer = Seq2SeqTrainer(\n","        model=custom_model,\n","        args=training_args,\n","        train_dataset=dataset[\"train\"],\n","        eval_dataset=dataset[\"test\"],\n","        tokenizer=tokenizer,\n","    )\n","\n","    # Start training\n","    trainer.train()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":592,"referenced_widgets":["84e18f1b8a9e4feda95f0b67ee130257","88afacb8a7ed4414b0187dcd19f381e9","3b1ce44aa19141b188ebd3ebc3f3e2a9","ff641886ac284b5ea8efe15184aa4924","eab5a1028e384d52b48dca1f3bb57bbb","f7794e4d04ea4ea1b963e5c35a048413","c9eb589bf37e4ed68e7af74d105e8bde","1653474ecce4475f8ebfa26f315638b0","0e80edea723f454aa7cd1b46761c62af","a1c0d7fdabbf4eee952890a67c5683df","9431f9ceb39144ed83a3d9dc74e32878","21da79a6c6b44911b5158e99eee64ea7","81b5d138f5a9431fb3653293ad0ab759","ea1e424424924defb54c7ea97e62afde","6b9ab4bd70f944fa9aa6e5baca468895","8d42e74a175b44faa4e902c8dd95a0cc","dae370e04f984e4a98705fc92856ba4e","dcb1ac8afc8b4417ac7ad0842c7be87a","c68df254779c4f70b5e5fa08f8d144b2","2375e84bba8e4b9e9c168afcd3112b1b","958fff98ae2848fa8933433409fcfbd5","865652bf3fc340b1a9adad32d97631e1","4547d6c1993f41a68b9dbf5e79c1d731","6624ebd90f184a24bf89a89ec5ab56e4","48286ffdc53a404bb3bab9133390aacb","90c78f2c313247f78df7e7fb3985f300","338bc4b6c82c468fbf067ba048177482","e6455d5781174794a9b0f224b4340d37","88ec17fc16bb45d4861ad7f429e89505","0d3f16c1f303461fad6db1d9e79b499f","cf67718d48484521b9478b61c7a056a4","a42a2c7eae16494fb6439850fcf385c2","ee50f1059584412183ecf412f8311628","302782dc05d045a3bebe35bde575d7e2","e350dee3ea6440c8a79b74e39c8a7f20","2798ab9adb814bbdb69e8e5c975a7bc8","9c7079141ff242aab4492936d9e5e728","68dacdda29814fd4be8601b99623897d","2edcfea482ed4d998399d23cb1485e3f","a5fa930ef5c24a809e9584d5b3e03e1b","6a5cadb177644826b8e81b792eee5bc4","6493cab1dac549af9c5387d96cdd8e1b","65345becc3c24d54b8a6232be2a81f4d","bdde231a7fc5453d91080cee98ed6598"]},"executionInfo":{"elapsed":2999807,"status":"ok","timestamp":1733533276316,"user":{"displayName":"Aaron Lin","userId":"11593436174117725897"},"user_tz":480},"id":"Ry4tYT3b6emd","outputId":"bec8e589-a5ac-4666-bc25-a383ec71c2db"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n","  warnings.warn(\"Recommended: pip install sacremoses.\")\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"84e18f1b8a9e4feda95f0b67ee130257","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/312M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"21da79a6c6b44911b5158e99eee64ea7","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4547d6c1993f41a68b9dbf5e79c1d731","version_major":2,"version_minor":0},"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Parameter 'function'=<function prepare_dataset.<locals>.preprocess_function at 0x784717e2bd00> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n","WARNING:datasets.fingerprint:Parameter 'function'=<function prepare_dataset.<locals>.preprocess_function at 0x784717e2bd00> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"302782dc05d045a3bebe35bde575d7e2","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/62127 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","<ipython-input-7-8b7fbb283a1f>:310: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n","  trainer = Seq2SeqTrainer(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maalin\u001b[0m (\u001b[33maalin-uc-berkeley\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.18.7"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20241207_001248-eiezgnnc</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/aalin-uc-berkeley/huggingface/runs/eiezgnnc' target=\"_blank\">/content/drive/MyDrive/266 Data Project/corpora/nejm/custom_models-mk3/</a></strong> to <a href='https://wandb.ai/aalin-uc-berkeley/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/aalin-uc-berkeley/huggingface' target=\"_blank\">https://wandb.ai/aalin-uc-berkeley/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/aalin-uc-berkeley/huggingface/runs/eiezgnnc' target=\"_blank\">https://wandb.ai/aalin-uc-berkeley/huggingface/runs/eiezgnnc</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3495' max='3495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3495/3495 48:19, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.690300</td>\n","      <td>2.576549</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n"]}],"source":["\n","# Configuration\n","model_name = \"Helsinki-NLP/opus-mt-zh-en\"\n","output_dir = \"/content/drive/MyDrive/266 Data Project/corpora/nejm/custom_models-mk3/\"\n","hidden_size = 512\n","\n","# Load named entities\n","named_entities_df = pd.read_parquet(\"/content/drive/MyDrive/266 Data Project/corpora/nejm/zh-entities.parquet\")\n","named_entities = [\"\".join(x) for x in named_entities_df[\"tokens\"].tolist()]\n","special_tokens = named_entities #[f\"{entity}\" for entity in named_entities]\n","special_token_size = len(special_tokens)\n","\n","# Load tokenizer and custom model\n","tokenizer, custom_model = load_marian_with_biomedical_layer(\n","    model_name,\n","    hidden_size,\n","    special_tokens\n",")\n","\n","# Load dataset\n","dataset = load_dataset(\"parquet\", data_files=\"/content/drive/MyDrive/266 Data Project/corpora/nejm/nejm_train_entities.parquet\")[\"train\"]\n","\n","# Prepare dataset\n","tokenized_dataset = prepare_dataset(\n","    dataset,\n","    tokenizer,\n","    src_lang=\"chinese\",\n","    tgt_lang=\"english\"\n",")\n","\n","# Before training\n","# Move all components to GPU before training\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","custom_model = custom_model.to(device)\n","# tokenizer = tokenizer.to(device)\n","\n","# Add explicit error checking\n","torch.cuda.empty_cache()  # Clear GPU memory before training\n","\n","# Fine-tune the model\n","fine_tune_custom_model(\n","    custom_model,\n","    tokenizer,\n","    tokenized_dataset,\n","    output_dir\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v_0QMR5TOfY8"},"outputs":[],"source":["import os\n","\n","# Set the environment variable\n","os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n","\n","# Import PyTorch after setting the environment variable\n","import torch\n","\n","# Optionally check if the variable is set correctly\n","print(\"PYTORCH_CUDA_ALLOC_CONF:\", os.environ.get('PYTORCH_CUDA_ALLOC_CONF'))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5RWEf2fELkfy"},"outputs":[],"source":["# Load dataset\n","# dataset = load_dataset(\"parquet\", data_files=\"/content/drive/MyDrive/266 Data Project/corpora/nejm/nejm_train_entities.parquet\")[\"train\"]\n","\n","# Configuration\n","model_name = \"Helsinki-NLP/opus-mt-zh-en\"\n","output_dir = \"/content/drive/MyDrive/266 Data Project/corpora/nejm/custom_models-mk3/\"\n","hidden_size = 512\n","\n","# Load named entities\n","named_entities_df = pd.read_parquet(\"/content/drive/MyDrive/266 Data Project/corpora/nejm/zh-entities.parquet\")\n","named_entities = [\"\".join(x) for x in named_entities_df[\"tokens\"].tolist()]\n","special_tokens = named_entities #[f\"{entity}\" for entity in named_entities]\n","special_token_size = len(special_tokens)\n","\n","# Load tokenizer and custom model\n","tokenizer, custom_model = load_marian_with_biomedical_layer(\n","    model_name,\n","    hidden_size,\n","    special_tokens\n",")\n","\n","tokenized_dataset = load_dataset(\"parquet\", data_files='/content/drive/MyDrive/266 Data Project/corpora/nejm/tokenized_512_zh.parquet')\n","\n","# Prepare dataset\n","tokenized_dataset = prepare_dataset(\n","    dataset,\n","    tokenizer,\n","    src_lang=\"chinese\",\n","    tgt_lang=\"english\"\n",")\n","\n","# Before training\n","# Move all components to GPU before training\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","custom_model = custom_model.to(device)\n","# tokenizer = tokenizer.to(device)\n","\n","# Add explicit error checking\n","torch.cuda.empty_cache()  # Clear GPU memory before training\n","\n","# Fine-tune the model\n","fine_tune_custom_model(\n","    custom_model,\n","    tokenizer,\n","    tokenized_dataset,\n","    output_dir\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0JJQOrZkIhMe"},"outputs":[],"source":["model_save_path = \"/content/drive/MyDrive/266 Data Project/corpora/nejm/before-training\"\n","# Loading custom model\n","custom_model, tokenizer = CustomMarianMTModel.from_custom(model_save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xaIjRUq0IYd-"},"outputs":[],"source":["tokenized_dataset = load_dataset(\"parquet\", data_files='/content/drive/MyDrive/266 Data Project/corpora/nejm/tokenized_512_zh.parquet')[\"train\"]\n","\n","output_dir = \"/content/drive/MyDrive/266 Data Project/corpora/nejm/custom_models-mk3/\"\n","\n","# Before training\n","# Move all components to GPU before training\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","custom_model = custom_model.to(device)\n","# tokenizer = tokenizer.to(device)\n","\n","# Add explicit error checking\n","torch.cuda.empty_cache()  # Clear GPU memory before training\n","\n","# Fine-tune the model\n","fine_tune_custom_model(\n","    custom_model,\n","    tokenizer,\n","    tokenized_dataset,\n","    output_dir\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["a26c44b8feb9451d944bf1cc483ac538","c551428e38a54e2483ef82d7840e2465","0b8bca59462e4c659f03b511f5afc59b","beec0038bf374b1f8b8bd19a405ac614","3c8f4c1f5150408b8a7118c79f781943","0cdbe0ba31f543c2b41a838806820abc","f56397f2aeff4d909112720739b1fa1f","76ccd0c87243402baca9bf629bbd5f0a","cd69cfc6b6394fbfbfdc22bb4e38d047","1a1d64d2378f4f1ea5cca23ca42849b1","28dc868f9f1141f48dabd6568c0752d3"]},"executionInfo":{"elapsed":1921,"status":"ok","timestamp":1733533278235,"user":{"displayName":"Aaron Lin","userId":"11593436174117725897"},"user_tz":480},"id":"woVpQX3hNx8S","outputId":"0589a945-ae48-49e0-d3a4-6e04e2403e70"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a26c44b8feb9451d944bf1cc483ac538","version_major":2,"version_minor":0},"text/plain":["Creating parquet from Arrow format:   0%|          | 0/63 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["416996424"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["tokenized_dataset.to_parquet('/content/drive/MyDrive/266 Data Project/corpora/nejm/non-special-tokenized_512_zh.parquet')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1733533278236,"user":{"displayName":"Aaron Lin","userId":"11593436174117725897"},"user_tz":480},"id":"Lpwdgtz9N1F5","outputId":"f8e3877a-ef11-4594-abc1-ca286cd3c5fb"},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['input_ids', 'attention_mask', 'labels', 'entity_ids'],\n","    num_rows: 62127\n","})"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["tokenized_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7387,"status":"ok","timestamp":1733533285621,"user":{"displayName":"Aaron Lin","userId":"11593436174117725897"},"user_tz":480},"id":"wQx4-HR_RYTP","outputId":"32e0f834-cef2-4457-919a-754c670d8ec4"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/266 Data Project/corpora/nejm/after-training-mk3/model\n"]}],"source":["# Saving custom model\n","model_save_path = \"/content/drive/MyDrive/266 Data Project/corpora/nejm/after-training-mk3\"\n","custom_model.save_custom(model_save_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r1JXRCbTsmmU"},"outputs":[],"source":["# model_save_path = \"/content/drive/MyDrive/266 Data Project/corpora/nejm/after-training-mk3\"\n","# # Loading custom model\n","# custom_model, tokenizer = CustomMarianMTModel.from_custom(model_save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5fS1Yk4GpnT_"},"outputs":[],"source":["from evaluate import load\n","import torch\n","\n","def add_special_tokens(tokenizer, entities):\n","    \"\"\"\n","    Adds new entity tokens to the tokenizer if they are not already present.\n","\n","    Args:\n","        tokenizer (transformers.PreTrainedTokenizer): The tokenizer to update.\n","        entities (list of str): List of entity names to add as special tokens.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    special_tokens = entities #[f\"{entity}\" for entity in entities]\n","    added_tokens = [token for token in special_tokens if token not in tokenizer.get_vocab()]\n","    if added_tokens:\n","        tokenizer.add_special_tokens({'additional_special_tokens': added_tokens})\n","        print(f\"Added new special tokens: {added_tokens}\")\n","\n","\n","def translate_tokenized_dataset(model, tokenizer, tokenized_dataset, batch_size=32):\n","    translations = []\n","\n","    model.eval()\n","\n","    for i in range(0, len(tokenized_dataset), batch_size):\n","        # Extract batch data\n","        input_ids = tokenized_dataset[\"input_ids\"][i:i + batch_size]\n","        attention_mask = tokenized_dataset[\"attention_mask\"][i:i + batch_size]\n","        entity_ids = tokenized_dataset[\"entity_ids\"][i:i + batch_size]\n","\n","        # Convert to tensors with explicit type and device handling\n","        input_ids = torch.tensor(input_ids, dtype=torch.long).to(model.device)\n","        attention_mask = torch.tensor(attention_mask, dtype=torch.long).to(model.device)\n","        entity_ids = torch.tensor(entity_ids, dtype=torch.long).to(model.device)\n","\n","        # Debug print statements\n","        print(f\"Batch {i//batch_size + 1}:\")\n","        print(f\"Input IDs shape: {input_ids.shape}\")\n","        print(f\"Attention Mask shape: {attention_mask.shape}\")\n","        print(f\"Entity IDs shape: {entity_ids.shape}\")\n","        print(f\"Entity IDs min: {entity_ids.min()}, max: {entity_ids.max()}\")\n","        print(f\"Model entity embedding size: {model.entity_embedding.num_embeddings}\")\n","\n","        # Validate entity_ids before generation\n","        try:\n","            # Check if all entity IDs are within the valid range\n","            assert torch.all(entity_ids >= 0), \"Negative entity IDs found\"\n","            assert torch.all(entity_ids < model.entity_embedding.num_embeddings), \"Out-of-bound entity IDs\"\n","        except AssertionError as e:\n","            print(f\"Entity ID validation error: {e}\")\n","            # Skip this batch or handle the error as needed\n","            continue\n","\n","        # Generate translations\n","        try:\n","            with torch.no_grad():\n","                outputs = model.generate(\n","                    input_ids=input_ids,\n","                    attention_mask=attention_mask,\n","                    entity_ids=entity_ids,\n","                    max_length=50,  # Increase this to the desired total length\n","                    num_beams=5,  # Optional: For beam search\n","                    do_sample=False  # Optional: To control randomness\n","                )\n","\n","        except Exception as e:\n","            print(f\"Generation error in batch {i//batch_size + 1}: {e}\")\n","            continue\n","\n","        # Decode translations\n","        translated_batch = [tokenizer.decode(t, skip_special_tokens=True) for t in outputs]\n","        translations.extend(translated_batch)\n","\n","    return translations\n","\n","\n","# Define evaluation metrics\n","def evaluate_model_metrics(predictions, references, save_path=None):\n","    # Load the evaluation metrics\n","    bleu_metric = load(\"bleu\")\n","    rouge_metric = load(\"rouge\")\n","    bertscore_metric = load(\"bertscore\")\n","    ter_metric = load(\"ter\")\n","\n","    # Format references for metric calculation\n","    references = [[ref] for ref in references]\n","\n","    # Evaluate BLEU score\n","    bleu_result = bleu_metric.compute(predictions=predictions, references=references)\n","\n","    # Evaluate ROUGE score\n","    rouge_result = rouge_metric.compute(predictions=predictions, references=references)\n","\n","    # Evaluate BERTScore\n","    bertscore_result = bertscore_metric.compute(predictions=predictions, references=references, lang=\"en\")\n","\n","    # Evaluate TER (Translation Edit Rate)\n","    ter_result = ter_metric.compute(predictions=predictions, references=references)\n","\n","    # Extract summary statistics for BERTScore\n","    bertscore_summary = {\n","        \"mean\": sum(bertscore_result[\"f1\"]) / len(bertscore_result[\"f1\"]),\n","        \"median\": sorted(bertscore_result[\"f1\"])[len(bertscore_result[\"f1\"]) // 2],\n","        \"std\": (sum((x - sum(bertscore_result[\"f1\"]) / len(bertscore_result[\"f1\"]))**2 for x in bertscore_result[\"f1\"]) / len(bertscore_result[\"f1\"]))**0.5\n","    }\n","\n","    # Consolidate results\n","    results = {\n","        \"BLEU\": bleu_result,\n","        \"ROUGE\": rouge_result,\n","        \"BERTScore\": bertscore_summary,\n","        \"TER\": ter_result,\n","    }\n","\n","    return results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mDdTQpxEpyuj"},"outputs":[],"source":["def preprocess_function(examples, tokenizer, src_lang=\"chinese\", max_entities=5):\n","    src_sentences = examples[src_lang]\n","    entities_list = examples.get(\"entities\", [[] for _ in src_sentences])\n","\n","    processed_src = []\n","    processed_entities = []\n","\n","    for sentence, entities in zip(src_sentences, entities_list):\n","        processed_src.append(sentence)\n","\n","        # Convert entities to token IDs (if in vocab)\n","        entity_ids = [\n","            tokenizer.convert_tokens_to_ids(entity)\n","            if entity in tokenizer.get_vocab() else 0\n","            for entity in entities\n","        ]\n","\n","        # Pad or truncate entity_ids\n","        entity_ids = entity_ids[:max_entities]\n","        entity_ids += [0] * (max_entities - len(entity_ids))  # Pad with zeros\n","        processed_entities.append(entity_ids)\n","\n","    # Tokenize the processed source sentences\n","    model_inputs = tokenizer(\n","        processed_src,\n","        max_length=512,\n","        truncation=True,\n","        padding=True,\n","        return_tensors=\"pt\"\n","    )\n","\n","    # Add entity_ids as a tensor to the inputs\n","    model_inputs[\"entity_ids\"] = torch.tensor(processed_entities, dtype=torch.long)\n","\n","    return model_inputs\n","\n","def preprocess_test_data(test_dataset, tokenizer, src_lang=\"chinese\", max_entities=5):\n","    \"\"\"\n","    Preprocess test data to tokenize inputs and add entity_ids for entity-based embeddings.\n","    \"\"\"\n","    # Wrap preprocess_function with fixed arguments\n","    def wrapped_preprocess_function(examples):\n","        return preprocess_function(\n","            examples, tokenizer=tokenizer, src_lang=src_lang, max_entities=max_entities\n","        )\n","\n","    # Apply the preprocessing function to the test dataset\n","    processed_test_dataset = test_dataset.map(\n","        wrapped_preprocess_function,\n","        batched=True,\n","        remove_columns=test_dataset.column_names,\n","    )\n","\n","    return processed_test_dataset\n","\n","\n","def evaluate_model(model, tokenized_test_dataset, tokenizer, batch_size=16):\n","    \"\"\"\n","    Evaluate the model on the tokenized test dataset.\n","    \"\"\"\n","    # Prepare DataLoader for test data\n","    test_loader = torch.utils.data.DataLoader(\n","        tokenized_test_dataset,\n","        batch_size=batch_size,\n","        shuffle=False,\n","        collate_fn=lambda batch: tokenizer.pad(batch, return_tensors=\"pt\")\n","    )\n","\n","    model.eval()\n","    predictions = []\n","\n","    with torch.no_grad():\n","        for batch in test_loader:\n","            # Move inputs to GPU if available\n","            inputs = {key: val.to(model.device) for key, val in batch.items() if key != \"labels\"}\n","\n","            # Generate predictions\n","            outputs = model.generate(**inputs)\n","            predictions.extend(outputs)\n","\n","    return predictions\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["90c11b3684d04ec0a6d9a6649e96cf34","0ca296539c0d4ebaa3c8bea85cbe35e5","5c5d3de941e94fe8ad8ddbf18879a771","fb188bb1884d4e77be787ae5a2539c61","6a215fa58ca14232a4966c9dc00ffe5a","de3c59c4bfe8438aa9b1180954de0565","a4d3d6609d694dc4b6a19c056b17ed45","9317ca6c277f4af8b0ddbd4af026bd2a","60b5aac5380e41698d0aee436133f983","57460e03374d418ab48b8c767cdefb1e","7fb414287e1b4ba4a374898636434443"]},"id":"BLXoJhm3p1Qb","outputId":"6d2b89c0-6169-4361-846c-3b3f69a1e988"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"90c11b3684d04ec0a6d9a6649e96cf34","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/2102 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Load your test dataset\n","test_dataset = load_dataset(\"parquet\", data_files={\"test\": \"/content/drive/MyDrive/266 Data Project/corpora/nejm/nejm_test_entities.parquet\"})[\"test\"]\n","\n","# Preprocess and tokenize test data\n","tokenized_test_dataset = preprocess_test_data(test_dataset, tokenizer)\n","\n","# # Evaluate model on test data\n","# predictions = evaluate_model(custom_model, tokenized_test_dataset, tokenizer)\n","# predictions[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"1lLGN2Lessqw","outputId":"bc4a29da-7e81-41f3-a9c1-48f15a256504"},"outputs":[{"data":{"text/plain":["tensor([65000,    59,  8263,    22,    59,  1232,   373,   618,  4545,  2318,\n","        16643,   571,  7114,   589,  2971,  1813,    59,  1490,     7,   466,\n","         2318,  8077,  8814,  2757,   250,  4545,  2872,  1044,  1843,  3602,\n","         2072,     7,   466,  4545,  2872,  1044,  1843,  3602,  2072,     7,\n","          466,  4545,  2872,  1044,  1843,  3602,  2072,     7,   466,  4545,\n","         2872,  1044,  1843,  3602,  2072,     7,   466,  4545,  2872,  1044,\n","         1843,  3602,  2072,     7,   466,  4545,  2872,  1044,  1843,  3602,\n","         2072,     7,   466,  4545,  2872,  1044,  1843,  3602,  2072,     7,\n","          466,  4545,  2872,  1044,  1843,  3602,  2072,     7,   466,  4545,\n","         2872,  1044,  1843,  3602,  2072,     7,   466,  4545,  2872,  1044,\n","         1843,  3602,  2072,     7,   466,  4545,  2872,  1044,  1843,  3602,\n","         2072,     7,   466,  4545,  2872,  1044,  1843,  3602,  2072,     7,\n","          466,  4545,  2872,  1044,  1843,  3602,  2072,     7,   466,  4545,\n","         2318,  8077,  8814,  2757,   250,  4545,  2872,  1044,  1843,  3602,\n","         2072,     7,   466,  4545,  2872,  1044,  1843,  3602,  2072,     7,\n","          466,  4545,  2872,  1044,  1843,  3602,  2072,     7,   466,  3906,\n","         1843,  3602,  2072,     7,   466,     5,     0, 65000, 65000, 65000,\n","        65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","        65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","        65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","        65000], device='cuda:0')"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# Evaluate model on test data\n","predictions = evaluate_model(custom_model, tokenized_test_dataset, tokenizer)\n","predictions[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"DBP8JLTfu1Wr","collapsed":true,"outputId":"ff70139b-0cc1-45d0-a9b7-b47d76a59ede"},"outputs":[{"data":{"text/plain":["['<pad>',\n"," 't',\n"," 'hi',\n"," 's',\n"," 't',\n"," 'r',\n"," 'i',\n"," 'al',\n"," 'w',\n"," 'as',\n"," 'si',\n"," 'g',\n"," 'ni',\n"," 'f',\n"," 'ic',\n"," 'an',\n"," 't',\n"," 'l',\n"," '▁',\n"," 'y',\n"," 'as',\n"," 'so',\n"," 'ci',\n"," 'at',\n"," 'ed',\n"," 'w',\n"," 'it',\n"," 'h',\n"," 'the',\n"," 'ra',\n"," 'p',\n"," '▁',\n"," 'y',\n"," 'w',\n"," 'it',\n"," 'h',\n"," 'the',\n"," 'ra',\n"," 'p',\n"," '▁',\n"," 'y',\n"," 'w',\n"," 'it',\n"," 'h',\n"," 'the',\n"," 'ra',\n"," 'p',\n"," '▁',\n"," 'y',\n"," 'w',\n"," 'it',\n"," 'h',\n"," 'the',\n"," 'ra',\n"," 'p',\n"," '▁',\n"," 'y',\n"," 'w',\n"," 'it',\n"," 'h',\n"," 'the',\n"," 'ra',\n"," 'p',\n"," '▁',\n"," 'y',\n"," 'w',\n"," 'it',\n"," 'h',\n"," 'the',\n"," 'ra',\n"," 'p',\n"," '▁',\n"," 'y',\n"," 'w',\n"," 'it',\n"," 'h',\n"," 'the',\n"," 'ra',\n"," 'p',\n"," '▁',\n"," 'y',\n"," 'w',\n"," 'it',\n"," 'h',\n"," 'the',\n"," 'ra',\n"," 'p',\n"," '▁',\n"," 'y',\n"," 'w',\n"," 'it',\n"," 'h',\n"," 'the',\n"," 'ra',\n"," 'p',\n"," '▁',\n"," 'y',\n"," 'w',\n"," 'it',\n"," 'h',\n"," 'the',\n"," 'ra',\n"," 'p',\n"," '▁',\n"," 'y',\n"," 'w',\n"," 'it',\n"," 'h',\n"," 'the',\n"," 'ra',\n"," 'p',\n"," '▁',\n"," 'y',\n"," 'w',\n"," 'it',\n"," 'h',\n"," 'the',\n"," 'ra',\n"," 'p',\n"," '▁',\n"," 'y',\n"," 'w',\n"," 'it',\n"," 'h',\n"," 'the',\n"," 'ra',\n"," 'p',\n"," '▁',\n"," 'y',\n"," 'w',\n"," 'as',\n"," 'so',\n"," 'ci',\n"," 'at',\n"," 'ed',\n"," 'w',\n"," 'it',\n"," 'h',\n"," 'the',\n"," 'ra',\n"," 'p',\n"," '▁',\n"," 'y',\n"," 'w',\n"," 'it',\n"," 'h',\n"," 'the',\n"," 'ra',\n"," 'p',\n"," '▁',\n"," 'y',\n"," 'w',\n"," 'it',\n"," 'h',\n"," 'the',\n"," 'ra',\n"," 'p',\n"," '▁',\n"," 'y',\n"," 'of',\n"," 'the',\n"," 'ra',\n"," 'p',\n"," '▁',\n"," 'y',\n"," '.',\n"," '</s>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>']"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["temp = tokenizer.convert_ids_to_tokens(predictions[0])\n","temp"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"p1IrWQLhvEc_"},"outputs":[],"source":["pd.DataFrame(data={\"predicted_english_tokens\": [x.cpu().numpy() for x in predictions]}).to_parquet(\"/content/drive/MyDrive/266 Data Project/corpora/nejm/mk3_post_training_predictions.parquet\")"]},{"cell_type":"code","source":["custom_model, tokenizer = CustomMarianMTModel.from_custom(\"/content/drive/MyDrive/266 Data Project/corpora/nejm/after-training-mk3\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bDeq2PbAAQ6-","executionInfo":{"status":"ok","timestamp":1733539827423,"user_tz":480,"elapsed":31480,"user":{"displayName":"Aaron Lin","userId":"11593436174117725897"}},"outputId":"f7f543ed-c178-42bf-c056-fae00f1ad25b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-8b7fbb283a1f>:140: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  biomedical_encoder_state_dict = torch.load(biomedical_encoder_path)\n","/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n","  warnings.warn(\"Recommended: pip install sacremoses.\")\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gMynXYNnvZ7b"},"outputs":[],"source":["# Decode predictions to text\n","decoded_predictions = [tokenizer.decode(pred, skip_special_tokens=True) for pred in predictions]\n","print(\"Predictions:\", decoded_predictions[0:5])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2_oAH54OKQUa"},"outputs":[],"source":["test_dataset[\"english\"][0:5]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RXzSKR8owB_W"},"outputs":[],"source":["pd.DataFrame(data={\"predicted_english\": decoded_predictions}).to_parquet(\"/content/drive/MyDrive/266 Data Project/corpora/nejm/mk3_post_training_predictions_detokenized.parquet\")"]},{"cell_type":"code","source":["pip install datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"8N1l1Bw78SAK","executionInfo":{"status":"ok","timestamp":1733538449978,"user_tz":480,"elapsed":15771,"user":{"displayName":"Aaron Lin","userId":"11593436174117725897"}},"outputId":"a5eb74ba-95c6-4c83-8319-bd0d9d9de473"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.9)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"]}]},{"cell_type":"code","source":["from datasets import load_dataset\n","import pandas as pd\n","test_dataset = load_dataset(\"parquet\", data_files={\"test\": \"/content/drive/MyDrive/266 Data Project/corpora/nejm/nejm_test_entities.parquet\"})[\"test\"]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["5a6bcfb4afef46ffb91efc460067267f","cd4acffb492144e6bc57712d2db01756","dce63d08de334a77909ff3e5de19192b","808d97f54410482f98d87fe48b16c95b","2cf202b97da64b89b4a7e67f7c377a48","2cbf5c8e915f4cd2908fa728af3ecbf6","9aec2ff8d9f84436b2ad86472277d458","f1c2d0902ae2487b8474eac8e8b6d3d6","8469c4fd325346f4890dcb6f5ad5a26e","524eeddcad4b4d609413256e698b00e3","586afdc70f9b401f9616cc360e5da960"]},"id":"fNc6Q7SU750C","executionInfo":{"status":"ok","timestamp":1733539286914,"user_tz":480,"elapsed":3928,"user":{"displayName":"Aaron Lin","userId":"11593436174117725897"}},"outputId":"f44f9d01-56eb-427b-c0c9-a08630ed2fa5"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Generating test split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a6bcfb4afef46ffb91efc460067267f"}},"metadata":{}}]},{"cell_type":"code","source":["predictions = pd.read_parquet('/content/drive/MyDrive/266 Data Project/corpora/nejm/mk3_post_training_predictions.parquet')[\"predicted_english_tokens\"]"],"metadata":{"id":"aAFhf9iE7CzH"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V5XO_d4s5xb6"},"outputs":[],"source":["results = evaluate_model_metrics(decoded_predictions, test_dataset[\"english\"])\n","results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JO5YQfR2L7Jd"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[{"file_id":"16a2vyMpbdmZbN7syh-7cKxcQEG8VZ9RR","timestamp":1733470113903}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0b8bca59462e4c659f03b511f5afc59b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_76ccd0c87243402baca9bf629bbd5f0a","max":63,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cd69cfc6b6394fbfbfdc22bb4e38d047","value":63}},"0ca296539c0d4ebaa3c8bea85cbe35e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de3c59c4bfe8438aa9b1180954de0565","placeholder":"​","style":"IPY_MODEL_a4d3d6609d694dc4b6a19c056b17ed45","value":"Map:  48%"}},"0cdbe0ba31f543c2b41a838806820abc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d3f16c1f303461fad6db1d9e79b499f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"0e80edea723f454aa7cd1b46761c62af":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1653474ecce4475f8ebfa26f315638b0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a1d64d2378f4f1ea5cca23ca42849b1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21da79a6c6b44911b5158e99eee64ea7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_81b5d138f5a9431fb3653293ad0ab759","IPY_MODEL_ea1e424424924defb54c7ea97e62afde","IPY_MODEL_6b9ab4bd70f944fa9aa6e5baca468895"],"layout":"IPY_MODEL_8d42e74a175b44faa4e902c8dd95a0cc"}},"2375e84bba8e4b9e9c168afcd3112b1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2798ab9adb814bbdb69e8e5c975a7bc8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a5cadb177644826b8e81b792eee5bc4","max":62127,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6493cab1dac549af9c5387d96cdd8e1b","value":62127}},"28dc868f9f1141f48dabd6568c0752d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2edcfea482ed4d998399d23cb1485e3f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"302782dc05d045a3bebe35bde575d7e2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e350dee3ea6440c8a79b74e39c8a7f20","IPY_MODEL_2798ab9adb814bbdb69e8e5c975a7bc8","IPY_MODEL_9c7079141ff242aab4492936d9e5e728"],"layout":"IPY_MODEL_68dacdda29814fd4be8601b99623897d"}},"338bc4b6c82c468fbf067ba048177482":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b1ce44aa19141b188ebd3ebc3f3e2a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1653474ecce4475f8ebfa26f315638b0","max":312087009,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0e80edea723f454aa7cd1b46761c62af","value":312087009}},"3c8f4c1f5150408b8a7118c79f781943":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4547d6c1993f41a68b9dbf5e79c1d731":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6624ebd90f184a24bf89a89ec5ab56e4","IPY_MODEL_48286ffdc53a404bb3bab9133390aacb","IPY_MODEL_90c78f2c313247f78df7e7fb3985f300"],"layout":"IPY_MODEL_338bc4b6c82c468fbf067ba048177482"}},"48286ffdc53a404bb3bab9133390aacb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d3f16c1f303461fad6db1d9e79b499f","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cf67718d48484521b9478b61c7a056a4","value":1}},"57460e03374d418ab48b8c767cdefb1e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c5d3de941e94fe8ad8ddbf18879a771":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_9317ca6c277f4af8b0ddbd4af026bd2a","max":2102,"min":0,"orientation":"horizontal","style":"IPY_MODEL_60b5aac5380e41698d0aee436133f983","value":1000}},"60b5aac5380e41698d0aee436133f983":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6493cab1dac549af9c5387d96cdd8e1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"65345becc3c24d54b8a6232be2a81f4d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6624ebd90f184a24bf89a89ec5ab56e4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6455d5781174794a9b0f224b4340d37","placeholder":"​","style":"IPY_MODEL_88ec17fc16bb45d4861ad7f429e89505","value":"Generating train split: "}},"68dacdda29814fd4be8601b99623897d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a215fa58ca14232a4966c9dc00ffe5a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a5cadb177644826b8e81b792eee5bc4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b9ab4bd70f944fa9aa6e5baca468895":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_958fff98ae2848fa8933433409fcfbd5","placeholder":"​","style":"IPY_MODEL_865652bf3fc340b1a9adad32d97631e1","value":" 293/293 [00:00&lt;00:00, 22.3kB/s]"}},"76ccd0c87243402baca9bf629bbd5f0a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7fb414287e1b4ba4a374898636434443":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"81b5d138f5a9431fb3653293ad0ab759":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dae370e04f984e4a98705fc92856ba4e","placeholder":"​","style":"IPY_MODEL_dcb1ac8afc8b4417ac7ad0842c7be87a","value":"generation_config.json: 100%"}},"84e18f1b8a9e4feda95f0b67ee130257":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_88afacb8a7ed4414b0187dcd19f381e9","IPY_MODEL_3b1ce44aa19141b188ebd3ebc3f3e2a9","IPY_MODEL_ff641886ac284b5ea8efe15184aa4924"],"layout":"IPY_MODEL_eab5a1028e384d52b48dca1f3bb57bbb"}},"865652bf3fc340b1a9adad32d97631e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"88afacb8a7ed4414b0187dcd19f381e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7794e4d04ea4ea1b963e5c35a048413","placeholder":"​","style":"IPY_MODEL_c9eb589bf37e4ed68e7af74d105e8bde","value":"pytorch_model.bin: 100%"}},"88ec17fc16bb45d4861ad7f429e89505":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8d42e74a175b44faa4e902c8dd95a0cc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90c11b3684d04ec0a6d9a6649e96cf34":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0ca296539c0d4ebaa3c8bea85cbe35e5","IPY_MODEL_5c5d3de941e94fe8ad8ddbf18879a771","IPY_MODEL_fb188bb1884d4e77be787ae5a2539c61"],"layout":"IPY_MODEL_6a215fa58ca14232a4966c9dc00ffe5a"}},"90c78f2c313247f78df7e7fb3985f300":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a42a2c7eae16494fb6439850fcf385c2","placeholder":"​","style":"IPY_MODEL_ee50f1059584412183ecf412f8311628","value":" 62127/0 [00:01&lt;00:00, 37929.29 examples/s]"}},"9317ca6c277f4af8b0ddbd4af026bd2a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9431f9ceb39144ed83a3d9dc74e32878":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"958fff98ae2848fa8933433409fcfbd5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c7079141ff242aab4492936d9e5e728":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_65345becc3c24d54b8a6232be2a81f4d","placeholder":"​","style":"IPY_MODEL_bdde231a7fc5453d91080cee98ed6598","value":" 62127/62127 [00:58&lt;00:00, 1054.38 examples/s]"}},"a1c0d7fdabbf4eee952890a67c5683df":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a26c44b8feb9451d944bf1cc483ac538":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c551428e38a54e2483ef82d7840e2465","IPY_MODEL_0b8bca59462e4c659f03b511f5afc59b","IPY_MODEL_beec0038bf374b1f8b8bd19a405ac614"],"layout":"IPY_MODEL_3c8f4c1f5150408b8a7118c79f781943"}},"a42a2c7eae16494fb6439850fcf385c2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4d3d6609d694dc4b6a19c056b17ed45":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a5fa930ef5c24a809e9584d5b3e03e1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bdde231a7fc5453d91080cee98ed6598":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"beec0038bf374b1f8b8bd19a405ac614":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a1d64d2378f4f1ea5cca23ca42849b1","placeholder":"​","style":"IPY_MODEL_28dc868f9f1141f48dabd6568c0752d3","value":" 63/63 [00:02&lt;00:00, 33.55ba/s]"}},"c551428e38a54e2483ef82d7840e2465":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0cdbe0ba31f543c2b41a838806820abc","placeholder":"​","style":"IPY_MODEL_f56397f2aeff4d909112720739b1fa1f","value":"Creating parquet from Arrow format: 100%"}},"c68df254779c4f70b5e5fa08f8d144b2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9eb589bf37e4ed68e7af74d105e8bde":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd69cfc6b6394fbfbfdc22bb4e38d047":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cf67718d48484521b9478b61c7a056a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dae370e04f984e4a98705fc92856ba4e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcb1ac8afc8b4417ac7ad0842c7be87a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"de3c59c4bfe8438aa9b1180954de0565":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e350dee3ea6440c8a79b74e39c8a7f20":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2edcfea482ed4d998399d23cb1485e3f","placeholder":"​","style":"IPY_MODEL_a5fa930ef5c24a809e9584d5b3e03e1b","value":"Map: 100%"}},"e6455d5781174794a9b0f224b4340d37":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea1e424424924defb54c7ea97e62afde":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c68df254779c4f70b5e5fa08f8d144b2","max":293,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2375e84bba8e4b9e9c168afcd3112b1b","value":293}},"eab5a1028e384d52b48dca1f3bb57bbb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee50f1059584412183ecf412f8311628":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f56397f2aeff4d909112720739b1fa1f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f7794e4d04ea4ea1b963e5c35a048413":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb188bb1884d4e77be787ae5a2539c61":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_57460e03374d418ab48b8c767cdefb1e","placeholder":"​","style":"IPY_MODEL_7fb414287e1b4ba4a374898636434443","value":" 1000/2102 [02:38&lt;02:54,  6.32 examples/s]"}},"ff641886ac284b5ea8efe15184aa4924":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1c0d7fdabbf4eee952890a67c5683df","placeholder":"​","style":"IPY_MODEL_9431f9ceb39144ed83a3d9dc74e32878","value":" 312M/312M [00:01&lt;00:00, 242MB/s]"}},"5a6bcfb4afef46ffb91efc460067267f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cd4acffb492144e6bc57712d2db01756","IPY_MODEL_dce63d08de334a77909ff3e5de19192b","IPY_MODEL_808d97f54410482f98d87fe48b16c95b"],"layout":"IPY_MODEL_2cf202b97da64b89b4a7e67f7c377a48"}},"cd4acffb492144e6bc57712d2db01756":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2cbf5c8e915f4cd2908fa728af3ecbf6","placeholder":"​","style":"IPY_MODEL_9aec2ff8d9f84436b2ad86472277d458","value":"Generating test split: "}},"dce63d08de334a77909ff3e5de19192b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1c2d0902ae2487b8474eac8e8b6d3d6","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8469c4fd325346f4890dcb6f5ad5a26e","value":1}},"808d97f54410482f98d87fe48b16c95b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_524eeddcad4b4d609413256e698b00e3","placeholder":"​","style":"IPY_MODEL_586afdc70f9b401f9616cc360e5da960","value":" 2102/0 [00:01&lt;00:00, 1476.84 examples/s]"}},"2cf202b97da64b89b4a7e67f7c377a48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cbf5c8e915f4cd2908fa728af3ecbf6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9aec2ff8d9f84436b2ad86472277d458":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f1c2d0902ae2487b8474eac8e8b6d3d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"8469c4fd325346f4890dcb6f5ad5a26e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"524eeddcad4b4d609413256e698b00e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"586afdc70f9b401f9616cc360e5da960":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}