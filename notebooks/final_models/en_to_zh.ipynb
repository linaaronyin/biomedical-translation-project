{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gaming\\anaconda3\\envs\\266-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "import gensim\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from tqdm.autonotebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Hoo-SrrUpxsF"
   },
   "outputs": [],
   "source": [
    "class TranslationDataset:\n",
    "    \"\"\"\n",
    "    Prepare tokenized datasets for training and evaluation without relying on DataLoader.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def prepare_dataset(english_texts, chinese_texts, tokenizer):\n",
    "        # Tokenize parallel corpus\n",
    "        tokenized_data = {\n",
    "            \"source\": tokenizer(\n",
    "                english_texts,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=128,\n",
    "                return_tensors='pt'\n",
    "            ),\n",
    "            \"target\": tokenizer(\n",
    "                chinese_texts,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=128,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "        }\n",
    "\n",
    "        # Prepare data dictionary for Hugging Face Dataset\n",
    "        dataset_dict = {\n",
    "            \"input_ids\": tokenized_data[\"source\"][\"input_ids\"],\n",
    "            \"attention_mask\": tokenized_data[\"source\"][\"attention_mask\"],\n",
    "            \"labels\": tokenized_data[\"target\"][\"input_ids\"]\n",
    "        }\n",
    "\n",
    "        # Convert to Hugging Face Dataset\n",
    "        return Dataset.from_dict({key: value.tolist() for key, value in dataset_dict.items()})\n",
    "\n",
    "\n",
    "class BiomedicalMarianMTEnhancer(nn.Module):\n",
    "    \"\"\"\n",
    "    Wraps MarianMT with additional medical term embeddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_model, tokenizer, biowordvec_path='C:\\\\Users\\\\Gaming\\\\Documents\\\\GitHub\\\\MIE2\\\\2024-fall-assignment-linaaron88\\\\project\\\\BioWordVec_PubMed_MIMICIII_d200.vec.bin'):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        # Load BioWordVec embeddings\n",
    "        print(biowordvec_path)\n",
    "        self.biowordvec = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "            biowordvec_path,\n",
    "            binary=True\n",
    "        )\n",
    "\n",
    "        # Create a custom embedding layer for medical terms\n",
    "        embedding_dim = self.biowordvec.vector_size\n",
    "        vocab_size = base_model.config.vocab_size\n",
    "\n",
    "        # Create a custom embedding layer\n",
    "        self.medical_embedding_layer = nn.Embedding(\n",
    "            vocab_size,\n",
    "            embedding_dim\n",
    "        )\n",
    "\n",
    "        # Initialize medical embedding layer\n",
    "        self._init_medical_embeddings()\n",
    "\n",
    "        # Additional projection layer to align embeddings\n",
    "        self.projection = nn.Linear(\n",
    "            embedding_dim,\n",
    "            base_model.config.d_model\n",
    "        )\n",
    "\n",
    "    def _init_medical_embeddings(self):\n",
    "        weight = self.medical_embedding_layer.weight.data\n",
    "\n",
    "        for token, idx in self.tokenizer.get_vocab().items():\n",
    "            clean_token = token.replace('‚ñÅ', '').strip()\n",
    "\n",
    "            try:\n",
    "                # Try to get embedding for the token\n",
    "                vec = self.biowordvec[clean_token]\n",
    "                weight[idx] = torch.tensor(vec)\n",
    "            except KeyError:\n",
    "                # Fallback to default initialization\n",
    "                nn.init.xavier_uniform_(weight[idx].unsqueeze(0))\n",
    "\n",
    "    def forward(self, input_ids, labels=None, attention_mask=None):\n",
    "        # Get base model embeddings\n",
    "        base_embeddings = self.base_model.model.get_input_embeddings()(input_ids)\n",
    "\n",
    "        # Get medical term embeddings\n",
    "        medical_embeddings = self.medical_embedding_layer(input_ids)\n",
    "\n",
    "        # Project medical embeddings\n",
    "        projected_medical_embeddings = self.projection(medical_embeddings)\n",
    "\n",
    "        # Combine base and medical embeddings\n",
    "        combined_embeddings = base_embeddings + projected_medical_embeddings\n",
    "\n",
    "        # Continue with standard MarianMT forward pass\n",
    "        outputs = self.base_model(\n",
    "            inputs_embeds=combined_embeddings,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        return outputs\n",
    "    \n",
    "    def generate(self, input_ids=None, attention_mask=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Generate translations with custom embeddings and pass them into MarianMT method as input_embeddings\n",
    "        \"\"\"\n",
    "        if input_ids is not None:\n",
    "            # Compute the base embeddings\n",
    "            base_embeddings = self.base_model.model.get_input_embeddings()(input_ids)\n",
    "\n",
    "            # Compute the medical term embeddings\n",
    "            medical_embeddings = self.medical_embedding_layer(input_ids)\n",
    "\n",
    "            # Project medical embeddings\n",
    "            projected_medical_embeddings = self.projection(medical_embeddings)\n",
    "\n",
    "            # Combine base and medical embeddings\n",
    "            combined_embeddings = base_embeddings + projected_medical_embeddings\n",
    "\n",
    "            # Use the combined embeddings for generation\n",
    "            return self.base_model.generate(\n",
    "                inputs_embeds=combined_embeddings,\n",
    "                attention_mask=attention_mask,\n",
    "                **kwargs\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"`input_ids` must be provided for generating embeddings.\")\n",
    "        \n",
    "    def save_custom(self, save_directory, tokenizer=None):\n",
    "        \"\"\"\n",
    "        Save the model and custom embeddings.\n",
    "        \"\"\"\n",
    "        os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "        # Paths\n",
    "        model_save_path = os.path.join(save_directory, \"model\")\n",
    "        embedding_save_path = os.path.join(model_save_path, \"medical_embeddings.pth\")\n",
    "        projection_save_path = os.path.join(model_save_path, \"projection_layer.pth\")\n",
    "        custom_config_path = os.path.join(model_save_path, \"custom_config.json\")\n",
    "        tokenizer_save_path = os.path.join(save_directory, \"tokenizer\")\n",
    "\n",
    "        os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "        # Save the base model\n",
    "        self.base_model.save_pretrained(model_save_path)\n",
    "\n",
    "        # Save the medical embedding and projection layer\n",
    "        torch.save(self.medical_embedding_layer.state_dict(), embedding_save_path)\n",
    "        torch.save(self.projection.state_dict(), projection_save_path)\n",
    "\n",
    "        # Save custom configuration\n",
    "        custom_config = {\n",
    "            \"embedding_dim\": self.medical_embedding_layer.embedding_dim,\n",
    "            \"vocab_size\": self.medical_embedding_layer.num_embeddings\n",
    "        }\n",
    "        with open(custom_config_path, \"w\") as f:\n",
    "            json.dump(custom_config, f)\n",
    "\n",
    "        # Save tokenizer\n",
    "        if tokenizer is not None:\n",
    "            tokenizer.save_pretrained(tokenizer_save_path)\n",
    "\n",
    "    @classmethod\n",
    "    def from_custom(cls, save_directory):\n",
    "        \"\"\"\n",
    "        Load the model and custom embeddings.\n",
    "        \"\"\"\n",
    "        # Paths\n",
    "        model_save_path = os.path.join(save_directory, \"model\")\n",
    "        embedding_save_path = os.path.join(model_save_path, \"medical_embeddings.pth\")\n",
    "        projection_save_path = os.path.join(model_save_path, \"projection_layer.pth\")\n",
    "        custom_config_path = os.path.join(model_save_path, \"custom_config.json\")\n",
    "        tokenizer_save_path = os.path.join(save_directory, \"tokenizer\")\n",
    "\n",
    "        # Load tokenizer\n",
    "        tokenizer = transformers.MarianTokenizer.from_pretrained(tokenizer_save_path)\n",
    "\n",
    "        # Load the base model\n",
    "        base_model = transformers.MarianMTModel.from_pretrained(model_save_path)\n",
    "\n",
    "        # Load custom configuration\n",
    "        with open(custom_config_path, \"r\") as f:\n",
    "            custom_config = json.load(f)\n",
    "\n",
    "        # Extract custom configuration values\n",
    "        embedding_dim = custom_config.get(\"embedding_dim\")\n",
    "        vocab_size = custom_config.get(\"vocab_size\")\n",
    "\n",
    "        # Create an instance of the enhanced model\n",
    "        enhancer = cls(\n",
    "            base_model=base_model,\n",
    "            tokenizer=tokenizer,  # Replace with tokenizer if required\n",
    "        )\n",
    "\n",
    "        # Resize and initialize the medical embedding layer based on the saved config\n",
    "        enhancer.medical_embedding_layer = nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=embedding_dim\n",
    "        )\n",
    "\n",
    "        # Load the medical embedding and projection layer states\n",
    "        medical_embedding_state = torch.load(embedding_save_path)\n",
    "        projection_state = torch.load(projection_save_path)\n",
    "        enhancer.medical_embedding_layer.load_state_dict(medical_embedding_state)\n",
    "        enhancer.projection.load_state_dict(projection_state)\n",
    "\n",
    "        return enhancer, tokenizer\n",
    "\n",
    "\n",
    "\n",
    "def train_biomedical_translation_model(\n",
    "    base_model,\n",
    "    tokenizer,\n",
    "    english_texts,\n",
    "    chinese_texts,\n",
    "    biowordvec_path,\n",
    "    test_size=0.1,\n",
    "    batch_size=16,\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=3,\n",
    "    output_dir=\"./results\"\n",
    "):\n",
    "    # Prepare datasets\n",
    "    full_dataset = TranslationDataset.prepare_dataset(english_texts, chinese_texts, tokenizer)\n",
    "    split_dataset = full_dataset.train_test_split(test_size=test_size, seed=42)\n",
    "\n",
    "    # Wrap the base model with the enhancer\n",
    "    enhanced_model = BiomedicalMarianMTEnhancer(\n",
    "        base_model,\n",
    "        tokenizer,\n",
    "        biowordvec_path\n",
    "    )\n",
    "\n",
    "    # Define Seq2Seq training arguments\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        weight_decay=0.01,\n",
    "        save_safetensors=False,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        logging_dir=\"./logs\",\n",
    "        logging_steps=500,\n",
    "        predict_with_generate=True,  # This is essential for seq2seq tasks like translation\n",
    "        generation_num_beams=4,  # Beam search during generation\n",
    "        # load_best_model_at_end=True\n",
    "    )\n",
    "\n",
    "    # Initialize Seq2SeqTrainer\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=enhanced_model,\n",
    "        args=training_args,\n",
    "        train_dataset=split_dataset[\"train\"],\n",
    "        eval_dataset=split_dataset[\"test\"],\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    return enhanced_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gaming\\anaconda3\\envs\\266-env\\Lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\Gaming\\AppData\\Local\\Temp\\ipykernel_7472\\1356813196.py:256: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maalin\u001b[0m (\u001b[33maalin-uc-berkeley\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Gaming\\Documents\\GitHub\\MIE2\\2024-fall-assignment-linaaron88\\project\\wandb\\run-20241207_094709-khnf6i12</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aalin-uc-berkeley/huggingface/runs/khnf6i12' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/aalin-uc-berkeley/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aalin-uc-berkeley/huggingface' target=\"_blank\">https://wandb.ai/aalin-uc-berkeley/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aalin-uc-berkeley/huggingface/runs/khnf6i12' target=\"_blank\">https://wandb.ai/aalin-uc-berkeley/huggingface/runs/khnf6i12</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|‚ñç         | 501/10485 [01:31<30:13,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.104, 'grad_norm': 1.0410629510879517, 'learning_rate': 9.523128278493086e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñâ         | 1001/10485 [03:02<28:41,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9542, 'grad_norm': 1.2827123403549194, 'learning_rate': 9.046256556986171e-05, 'epoch': 0.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|‚ñà‚ñç        | 1501/10485 [04:32<27:01,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.898, 'grad_norm': 1.0106414556503296, 'learning_rate': 8.569384835479256e-05, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|‚ñà‚ñâ        | 2001/10485 [06:02<25:25,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8579, 'grad_norm': 1.1509881019592285, 'learning_rate': 8.092513113972342e-05, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|‚ñà‚ñà‚ñç       | 2501/10485 [07:33<24:12,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7751, 'grad_norm': 1.3229390382766724, 'learning_rate': 7.615641392465427e-05, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|‚ñà‚ñà‚ñä       | 3001/10485 [09:04<22:39,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6159, 'grad_norm': 1.4556788206100464, 'learning_rate': 7.138769670958512e-05, 'epoch': 0.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 3495/10485 [10:58<19:43,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4532158076763153, 'eval_runtime': 23.7015, 'eval_samples_per_second': 262.135, 'eval_steps_per_second': 16.412, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 3501/10485 [11:00<2:49:35,  1.46s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.512, 'grad_norm': 1.518500804901123, 'learning_rate': 6.661897949451598e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 4001/10485 [12:30<19:29,  5.55it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4448, 'grad_norm': 1.333016276359558, 'learning_rate': 6.185026227944683e-05, 'epoch': 1.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 4501/10485 [14:00<17:50,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4139, 'grad_norm': 0.8244467973709106, 'learning_rate': 5.7081545064377684e-05, 'epoch': 1.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 5001/10485 [15:30<16:30,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3897, 'grad_norm': 1.1088536977767944, 'learning_rate': 5.2312827849308544e-05, 'epoch': 1.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 5501/10485 [16:59<14:55,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3825, 'grad_norm': 1.311639428138733, 'learning_rate': 4.754411063423939e-05, 'epoch': 1.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 6001/10485 [18:29<13:29,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3704, 'grad_norm': 1.1753039360046387, 'learning_rate': 4.2775393419170244e-05, 'epoch': 1.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 6501/10485 [19:59<11:57,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3532, 'grad_norm': 1.1417341232299805, 'learning_rate': 3.80066762041011e-05, 'epoch': 1.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6990/10485 [21:49<09:27,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.335773766040802, 'eval_runtime': 22.875, 'eval_samples_per_second': 271.606, 'eval_steps_per_second': 17.005, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 7001/10485 [21:52<22:12,  2.61it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.345, 'grad_norm': 1.3449496030807495, 'learning_rate': 3.323795898903195e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 7501/10485 [23:21<09:01,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.309, 'grad_norm': 0.9399582147598267, 'learning_rate': 2.8469241773962807e-05, 'epoch': 2.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 8001/10485 [24:51<07:30,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2977, 'grad_norm': 0.895879864692688, 'learning_rate': 2.3700524558893657e-05, 'epoch': 2.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8501/10485 [26:21<05:58,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2991, 'grad_norm': 1.0221785306930542, 'learning_rate': 1.8931807343824514e-05, 'epoch': 2.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 9001/10485 [27:51<04:28,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2989, 'grad_norm': 1.0727914571762085, 'learning_rate': 1.4163090128755365e-05, 'epoch': 2.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 9501/10485 [29:21<02:56,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2904, 'grad_norm': 0.9679888486862183, 'learning_rate': 9.394372913686218e-06, 'epoch': 2.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 10001/10485 [30:51<01:27,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.292, 'grad_norm': 0.9334255456924438, 'learning_rate': 4.6256556986170724e-06, 'epoch': 2.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10485/10485 [32:42<00:00,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3116215467453003, 'eval_runtime': 23.1653, 'eval_samples_per_second': 268.203, 'eval_steps_per_second': 16.792, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10485/10485 [32:44<00:00,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1966.5563, 'train_samples_per_second': 85.297, 'train_steps_per_second': 5.332, 'train_loss': 0.49984790254446454, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "# Load pretrained MarianMT model\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-zh\"\n",
    "tokenizer = transformers.MarianTokenizer.from_pretrained(model_name)\n",
    "base_model = transformers.MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "# Load your parallel corpus\n",
    "dataset = pd.read_parquet(\"C:\\\\Users\\\\Gaming\\\\Documents\\\\GitHub\\\\MIE2\\\\2024-fall-assignment-linaaron88\\\\project\\\\nejm\\\\nejm_train.parquet\")\n",
    "english_texts = dataset[\"english\"].tolist()\n",
    "chinese_texts = dataset[\"chinese\"].tolist()\n",
    "\n",
    "# Train the biomedical translation model\n",
    "enhanced_model = train_biomedical_translation_model(\n",
    "    base_model,\n",
    "    tokenizer,\n",
    "    english_texts,\n",
    "    chinese_texts,\n",
    "    biowordvec_path='C:\\\\Users\\\\Gaming\\\\Documents\\\\GitHub\\\\MIE2\\\\2024-fall-assignment-linaaron88\\\\project\\\\BioWordVec_PubMed_MIMICIII_d200.vec.bin',\n",
    "    num_train_epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gaming\\anaconda3\\envs\\266-env\\Lib\\site-packages\\transformers\\modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[65000]]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "save_dir = \".//saved_embedding_model\"\n",
    "enhanced_model.save_custom(save_dir, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5fS1Yk4GpnT_"
   },
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "def evaluate_model_metrics(predictions, references, save_path=None):\n",
    "    # Load the evaluation metrics\n",
    "    bleu_metric = load(\"bleu\")\n",
    "    rouge_metric = load(\"rouge\")\n",
    "    bertscore_metric = load(\"bertscore\")\n",
    "    ter_metric = load(\"ter\")\n",
    "\n",
    "    # Format references for metric calculation\n",
    "    references = [[ref] for ref in references]\n",
    "\n",
    "    # Evaluate BLEU score\n",
    "    bleu_result = bleu_metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "    # Evaluate ROUGE score\n",
    "    rouge_result = rouge_metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "    # Evaluate BERTScore\n",
    "    bertscore_result = bertscore_metric.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "\n",
    "    # Evaluate TER (Translation Edit Rate)\n",
    "    ter_result = ter_metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "    # Extract summary statistics for BERTScore\n",
    "    bertscore_summary = {\n",
    "        \"mean\": sum(bertscore_result[\"f1\"]) / len(bertscore_result[\"f1\"]),\n",
    "        \"median\": sorted(bertscore_result[\"f1\"])[len(bertscore_result[\"f1\"]) // 2],\n",
    "        \"std\": (sum((x - sum(bertscore_result[\"f1\"]) / len(bertscore_result[\"f1\"]))**2 for x in bertscore_result[\"f1\"]) / len(bertscore_result[\"f1\"]))**0.5\n",
    "    }\n",
    "\n",
    "    # Consolidate results\n",
    "    results = {\n",
    "        \"BLEU\": bleu_result,\n",
    "        \"ROUGE\": rouge_result,\n",
    "        \"BERTScore\": bertscore_summary,\n",
    "        \"TER\": ter_result,\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiomedicalTranslationEvaluator:\n",
    "    \"\"\"\n",
    "    Evaluate the performance of a biomedical translation model.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, tokenizer, device=None):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Move model to the specified device\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def prepare_dataset(self, english_texts, chinese_texts, max_length=512):\n",
    "        \"\"\"\n",
    "        Prepare a dataset for evaluation.\n",
    "        \"\"\"\n",
    "        # Tokenize source (English) texts\n",
    "        source_encodings = self.tokenizer(\n",
    "            english_texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # Tokenize target (Chinese) texts for comparison (optional)\n",
    "        target_encodings = self.tokenizer(\n",
    "            chinese_texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # Move all tensors to the appropriate device\n",
    "        return {\n",
    "            \"source_input_ids\": source_encodings[\"input_ids\"].to(self.device),\n",
    "            \"source_attention_mask\": source_encodings[\"attention_mask\"].to(self.device),\n",
    "            \"target_input_ids\": target_encodings[\"input_ids\"].to(self.device)\n",
    "        }\n",
    "\n",
    "    def generate_translations(self, dataset, batch_size=16):\n",
    "        translations = []\n",
    "        for i in trange(0, len(dataset[\"source_input_ids\"]), batch_size):\n",
    "            batch_input_ids = dataset[\"source_input_ids\"][i:i + batch_size].to(self.device)\n",
    "            batch_attention_mask = dataset[\"source_attention_mask\"][i:i + batch_size].to(self.device)\n",
    "\n",
    "            # Generate translations for the batch\n",
    "            outputs = self.model.generate(\n",
    "                input_ids=batch_input_ids,\n",
    "                attention_mask=batch_attention_mask,\n",
    "                num_beams=3,\n",
    "                max_length=128,  # Adjust if needed\n",
    "            )\n",
    "            translations.extend(self.tokenizer.batch_decode(outputs, skip_special_tokens=True))\n",
    "\n",
    "        return translations\n",
    "\n",
    "\n",
    "    def run_evaluation(self, english_texts, chinese_texts):\n",
    "        \"\"\"\n",
    "        Run the evaluation process.\n",
    "        \"\"\"\n",
    "        # Prepare dataset\n",
    "        dataset = self.prepare_dataset(english_texts, chinese_texts)\n",
    "\n",
    "        # Generate translations\n",
    "        translations = self.generate_translations(dataset)\n",
    "\n",
    "        # Decode target inputs for human-readable comparison\n",
    "        target_texts = self.tokenizer.batch_decode(\n",
    "            dataset[\"target_input_ids\"].to(\"cpu\"), skip_special_tokens=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"translations\": translations,\n",
    "            \"targets\": target_texts\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gaming\\Documents\\GitHub\\MIE2\\2024-fall-assignment-linaaron88\\project\\BioWordVec_PubMed_MIMICIII_d200.vec.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gaming\\AppData\\Local\\Temp\\ipykernel_18292\\2594061840.py:206: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  medical_embedding_state = torch.load(embedding_save_path)\n",
      "C:\\Users\\Gaming\\AppData\\Local\\Temp\\ipykernel_18292\\2594061840.py:207: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  projection_state = torch.load(projection_save_path)\n"
     ]
    }
   ],
   "source": [
    "save_dir = \".//saved_embedding_model\"\n",
    "enhanced_model, tokenizer = BiomedicalMarianMTEnhancer.from_custom(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 132/132 [05:07<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translations:\n",
      "['ÊòØ ‰∏ÄÁßç   , ÂÆÉ ÁªìÂêà ‰∫Ü BCR - ABL1  ÁöÑ ‰∏Ä‰∏™   , ÈÄöËøá ‰∏é ÊâÄÊúâ ÂÖ∂‰ªñ ABL   ‰∏çÂêå ÁöÑ Êú∫Âà∂ , Â∞Ü BCR - ABL1   .', '‚Ä¢  BCR - ABL1 ÁöÑ    , ÂåÖÊã¨  T315I  .', 'Âú®     ÊÇ£ËÄÖ ‰∏≠ ,   ÁöÑ  Âíå   Â∞ö ‰∏ç Ê∏ÖÊ•ö .', 'Âú® ËøôÈ°π 1 Êúü ÂâÇÈáè  Á†îÁ©∂ ‰∏≠ , Êàë‰ª¨ Á∫≥ÂÖ• ‰∫Ü 141 ‰æã ÊÖ¢ÊÄß  Âíå 9 ‰æã  ÊÖ¢ÊÄß   ( CML ) ÊÇ£ËÄÖ , Ëøô‰∫õ ÊÇ£ËÄÖ ÂØπ ‰πãÂâç Ëá≥Â∞ë Êúâ ‰∏§Áßç ATP     ( TKI ) ‰∫ßÁîü ÁöÑ  Êàñ Êó†Ê≥ï Êé•Âèó ÁöÑ  ‰∫ßÁîü  .', '‰∏ªË¶Å ÁõÆÁöÑ ÊòØ Á°ÆÂÆö ÊúÄÂ§ß  ÂâÇÈáè Êàñ Êé®Ëçê ÂâÇÈáè ( Êàñ ‰∏§ËÄÖ ) ÁöÑ   .']\n",
      "\n",
      "Targets:\n",
      "['asciminib ÊòØ ‰∏é BCR - ABL1  ÁöÑ  ÈÖ∞  Áõ∏ÁªìÂêà ÁöÑ  ÂâÇ , ÂÆÉ ÂèØ ÈÄöËøá ‰∏çÂêå‰∫é ÊâÄÊúâ ÂÖ∂‰ªñ ABL   ÁöÑ Êú∫Âà∂ Â∞Ü BCR - ABL1 ÈîÅÂÆö Âú® Èùû   .', 'asciminib ÂêåÊó∂  ‰ΩúÁî® ‰∫é Â§©ÁÑ∂ Âíå  ÁöÑ BCR - ABL1 , ÂåÖÊã¨  Âü∫Âõ† ( gatekeeper ) T315I  .', 'asciminib Áî®‰∫é     ÊÇ£ËÄÖ ÁöÑ  Âíå Êäó   Â∞öÊú™ ÊòéÁ°Æ .', 'Âú® ËøôÈ°π 1 Êúü ÂâÇÈáè  Á†îÁ©∂ ‰∏≠ , Êàë‰ª¨ Á∫≥ÂÖ• ‰∫Ü 141 ‰æã  Âíå 9 ‰æã Âä†ÈÄü Êúü ÊÖ¢ÊÄß   ( CML ) ÊÇ£ËÄÖ , Ëøô‰∫õ ÊÇ£ËÄÖ  ÂØπ Ëá≥Â∞ë ‰∏§Áßç ATP Á´û‰∫âÊÄß    ( TKI )  Êàñ ÂèëÁîü ‰∏çÂèØ Êé•Âèó ÁöÑ  .', 'Êú¨ ËØïÈ™å ÁöÑ ‰∏ªË¶Å ÁõÆÁöÑ ÊòØ Á°ÆÂÆö asciminib ÁöÑ ÊúÄÂ§ß  ÂâÇÈáè Êàñ Êé®Ëçê ÂâÇÈáè ( Êàñ Ëøô ‰∏§ËÄÖ ) .']\n"
     ]
    }
   ],
   "source": [
    "# Initialize the evaluator\n",
    "evaluator = BiomedicalTranslationEvaluator(\n",
    "    enhanced_model,\n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "test_dataset = pd.read_parquet(\"C:\\\\Users\\\\Gaming\\\\Documents\\\\GitHub\\\\MIE2\\\\2024-fall-assignment-linaaron88\\\\project\\\\nejm\\\\nejm_test.parquet\")\n",
    "english_test_texts = test_dataset[\"english\"].tolist()\n",
    "chinese_test_texts = test_dataset[\"chinese\"].tolist()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "# Run evaluation\n",
    "results = evaluator.run_evaluation(\n",
    "    english_test_texts,  # List of English sentences\n",
    "    chinese_test_texts   # List of Chinese reference translations\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(\"Translations:\")\n",
    "print(results[\"translations\"][0:5])\n",
    "print(\"\\nTargets:\")\n",
    "print(results[\"targets\"][0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asciminib is an allosteric inhibitor that binds a myristoyl site of the BCR @-@ ABL1 protein , locking BCR @-@ ABL1 into an inactive conformation through a mechanism distinct from those for all other ABL kinase inhibitors .'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[\"english\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7.95k/7.95k [00:00<00:00, 7.94MB/s]\n",
      "Downloading builder script: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9.99k/9.99k [00:00<?, ?B/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': {'bleu': 0.38178167014553976,\n",
       "  'precisions': [0.7368004631416442,\n",
       "   0.47385673490729197,\n",
       "   0.3332773708841367,\n",
       "   0.2465452950208379],\n",
       "  'brevity_penalty': 0.9276629254558418,\n",
       "  'length_ratio': 0.9301574195401268,\n",
       "  'translation_length': 51820,\n",
       "  'reference_length': 55711},\n",
       " 'ROUGE': {'rouge1': 0.5572755308465489,\n",
       "  'rouge2': 0.3422585235701242,\n",
       "  'rougeL': 0.5463369893398838,\n",
       "  'rougeLsum': 0.5470428823339599},\n",
       " 'BERTScore': {'mean': 0.9302092782663913,\n",
       "  'median': 0.9339444637298584,\n",
       "  'std': 0.06674159867862674},\n",
       " 'TER': {'score': 46.32471801950705,\n",
       "  'num_edits': 25505,\n",
       "  'ref_length': 55057.0}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_metrics(results[\"translations\"], results[\"targets\"])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "266-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
